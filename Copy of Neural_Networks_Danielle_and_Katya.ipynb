{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1gLh7XiU_X0YQjgPJnjooO-zD-IFgzv7x","timestamp":1713276386537}],"gpuType":"T4","authorship_tag":"ABX9TyOjRFFqCMzcI48Znd+PYxlv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l20KkIZTpbPs","executionInfo":{"status":"ok","timestamp":1712323604323,"user_tz":-180,"elapsed":27874,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"a7417a1d-e8b7-475e-dce0-71bc52e693dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m961.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.0)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6.2.2\n","\u001b[31mERROR: Could not find a version that satisfies the requirement language_models (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for language_models\u001b[0m\u001b[31m\n","\u001b[0mFound GPU at: /device:GPU:0\n","Cloning into 'language_models'...\n","remote: Enumerating objects: 106, done.\u001b[K\n","remote: Total 106 (delta 0), reused 0 (delta 0), pack-reused 106\u001b[K\n","Receiving objects: 100% (106/106), 19.38 MiB | 20.33 MiB/s, done.\n","Resolving deltas: 100% (55/55), done.\n"]}],"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","!pip install tensorboardX\n","!pip install language_models\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","# !git clone https://github.com/pbloem/language-models.git\n","!git clone https://github.com/GuyKabiri/language_models"]},{"cell_type":"code","source":["!pwd\n","##!git clone https://github.com/GuyKabiri/language_models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlgOF7Jzpe1j","executionInfo":{"status":"ok","timestamp":1712323620668,"user_tz":-180,"elapsed":262,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"1d4b6514-0a8b-463c-fd65-2ecca4e7f273"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["import keras\n","\n","import keras.backend as K\n","from keras.datasets import imdb\n","from keras.layers import  LSTM, Embedding, TimeDistributed, Input, Dense\n","from keras.models import Model\n","from tensorflow.python.client import device_lib\n","\n","from tqdm import tqdm\n","import os, random\n","\n","from argparse import ArgumentParser\n","\n","import numpy as np\n","\n","from tensorboardX import SummaryWriter\n","\n","from language_models import util\n","\n","CHECK = 5"],"metadata":{"id":"9RVPadyPpjWL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_seq(model : Model, seed, size, temperature=1.0):\n","    \"\"\"\n","    :param model: The complete RNN language model\n","    :param seed: The first few wordas of the sequence to start generating from\n","    :param size: The total size of the sequence to generate\n","    :param temperature: This controls how much we follow the probabilities provided by the network. For t=1.0 we just\n","        sample directly according to the probabilities. Lower temperatures make the high-probability words more likely\n","        (providing more likely, but slightly boring sentences) and higher temperatures make the lower probabilities more\n","        likely (resulting is weirder sentences). For temperature=0.0, the generation is _greedy_, i.e. the word with the\n","        highest probability is always chosen.\n","    :return: A list of integers representing a samples sentence\n","    \"\"\"\n","\n","    ls = seed.shape[0]\n","\n","    # Due to the way Keras RNNs work, we feed the model a complete sequence each time. At first it's just the seed,\n","    # zero-padded to the right length. With each iteration we sample and set the next character.\n","\n","    tokens = np.concatenate([seed, np.zeros(size - ls)])\n","\n","    for i in range(ls, size):\n","\n","        probs = model.predict(tokens[None,:])\n","\n","        # Extract the i-th probability vector and sample an index from it\n","        next_token = util.sample_logits(probs[0, i-1, :], temperature=temperature)\n","\n","        tokens[i] = next_token\n","\n","    return [int(t) for t in tokens]"],"metadata":{"id":"Sl2UnBasQCWW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sparse_loss(y_true, y_pred):\n","    return K.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"],"metadata":{"id":"qnly_0wCp267"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Args:\n","  epochs = 20 # Number of epochs\n","  embedding_size = 300 # Size of the word embeddings on the input layer.\n","  out_every = 1 # Output every n epochs.\n","  lr = 0.001 # Learning rate\n","  batch = 128 # Batch size\n","  task = 'wikisimple'\n","  data = './data' # Data file. Should contain one sentence per line.\n","  lstm_capacity = 256\n","  max_length = None # Sentence max length.\n","  top_words = 10000 # Word list size.\n","  limit = None # Character cap for the corpus - not relevant in our exercise.\n","  tb_dir = './runs/words' # Tensorboard directory\n","  seed = -1 # RNG seed. Negative for random (seed is printed for reproducability).\n","  extra = None # Number of extra LSTM layers.\n","\n","options = Args()"],"metadata":{"id":"1Xh7wytUp39b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense\n","from tensorflow.keras.models import Model\n","\n","def create_custom_model(extra_layers, is_backward):\n","    # Define input layer\n","    input_layer = Input(shape=(None,))\n","\n","    # Define embedding layer\n","    embedding_layer = Embedding(numwords, options.embedding_size, input_length=None)(input_layer)\n","\n","    # Apply embedding layer\n","    embedded = embedding_layer\n","\n","    # Define LSTM layer\n","    lstm_layer = LSTM(options.lstm_capacity, return_sequences=True, go_backwards=is_backward)(embedded)\n","\n","    # Add extra LSTM layers if specified\n","    if extra_layers is not None:\n","        for _ in range(extra_layers):\n","            lstm_layer = LSTM(options.lstm_capacity, return_sequences=True, go_backwards=is_backward)(lstm_layer)\n","\n","    # Define output layer\n","    output_layer = TimeDistributed(Dense(numwords, activation='linear'))(lstm_layer)\n","\n","    # Create model\n","    model = Model(input_layer, output_layer)\n","\n","    # Compile model\n","    opt = tf.keras.optimizers.Adam(lr=options.lr)\n","    lss = sparse_loss\n","    model.compile(opt, lss)\n","\n","    # Print model summary\n","    model.summary()\n","\n","    return model\n","\n"],"metadata":{"id":"1SnYm05DuT1W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if options.seed < 0:\n","    seed = random.randint(0, 1000000)\n","    print('random seed: ', seed)\n","    np.random.seed(seed)\n","else:\n","    np.random.seed(options.seed)\n","\n","if options.task == 'wikisimple':\n","\n","    x, w2i, i2w = util.load_words(util.DIR + '/datasets/wikisimple.txt', vocab_size=options.top_words, limit=options.limit)\n","\n","    # Finding the length of the longest sequence\n","    x_max_len = max([len(sentence) for sentence in x])\n","\n","    numwords = len(i2w)\n","    print('max sequence length ', x_max_len)\n","    print(numwords, 'distinct words')\n","\n","    x = util.batch_pad(x, options.batch, add_eos=True)\n","\n","elif options.task == 'file':\n","\n","    x, w2i, i2w = util.load_words(options.data_dir, vocab_size=options.top_words, limit=options.limit)\n","\n","    # Finding the length of the longest sequence\n","    x_max_len = max([len(sentence) for sentence in x])\n","\n","    numwords = len(i2w)\n","    print('max sequence length ', x_max_len)\n","    print(numwords, 'distinct words')\n","\n","    x = util.batch_pad(x, options.batch, add_eos=True)\n","\n","else:\n","    raise Exception('Task {} not recognized.'.format(options.task))\n","\n","def decode(seq):\n","    return ' '.join(i2w[id] for id in seq)\n","\n","print('Finished data loading. ', sum([b.shape[0] for b in x]), ' sentences loaded')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vd1e1WsJTrCT","executionInfo":{"status":"ok","timestamp":1712323643595,"user_tz":-180,"elapsed":1599,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"91a1e1c8-aec4-4424-ac56-14dd623da038"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["random seed:  192316\n","raw data read\n","max sequence length  132\n","10000 distinct words\n","max length per batch:  [15, 15, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 34, 34, 34, 34, 35, 35, 35, 35, 36, 36, 36, 37, 37, 38, 38, 39, 39, 40, 40, 41, 42, 42, 43, 44, 45, 46, 47, 48, 50, 52, 55, 60, 75, 133]\n","Finished data loading.  29741  sentences loaded\n"]}]},{"cell_type":"code","source":["import torch\n","tbw = SummaryWriter(log_dir=options.tb_dir)\n","\n","#- Since we have a variable batch size, we make our own training loop, and train with\n","#  model.train_on_batch(...). It's a little more verbose, but it gives us more control.\n","\n","def train_model(model, title):\n","  epoch = 0\n","  #instances_seen = 0\n","  while epoch < options.epochs:\n","      for batch in tqdm(train_data):\n","          n, l = batch.shape\n","\n","          batch_shifted = np.concatenate([np.ones((n, 1)), batch], axis=1)  # prepend start symbol\n","          batch_out = np.concatenate([batch, np.zeros((n, 1))], axis=1)     # append pad symbol\n","\n","          loss = model.train_on_batch(batch_shifted, batch_out[:, :, None])\n","      print(loss)\n","      epoch += 1\n","  return loss"],"metadata":{"id":"an-h5ggkp6QE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["****Q1:Splitting the dataset into train, validation, and test sets*****"],"metadata":{"id":"gqxzMydUrKO_"}},{"cell_type":"code","source":["import torch\n","train_data, valid_data, test_data = torch.utils.data.random_split(x, [int(len(x)*0.8),int(len(x)*0.1),int(len(x)*0.1)+1])\n","\n","\n"],"metadata":{"id":"7N46wb2zp_GP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["****Q2: calculate perplexity****"],"metadata":{"id":"0qpipodis6nP"}},{"cell_type":"code","source":["def calculate_perplexity(cEntropy):\n","    return 2 ** (cEntropy)\n"],"metadata":{"id":"2_hfi8s2s7Mc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["****Q3: All we need to do is to change the value of the flag 'backword' to 'TRUE' ****"],"metadata":{"id":"2Gnu28hqv7OR"}},{"cell_type":"markdown","source":["*****Q4: # No extra layers, forward direction ****"],"metadata":{"id":"L0wd2t-NwJme"}},{"cell_type":"code","source":["model1 = create_custom_model(None, False)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AwAhrkGmxCjn","executionInfo":{"status":"ok","timestamp":1712323654779,"user_tz":-180,"elapsed":1324,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"1b230950-bc5b-4ebd-c117-391c5f525309"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding (Embedding)       (None, None, 300)         3000000   \n","                                                                 \n"," lstm (LSTM)                 (None, None, 256)         570368    \n","                                                                 \n"," time_distributed (TimeDist  (None, None, 10000)       2570000   \n"," ributed)                                                        \n","                                                                 \n","=================================================================\n","Total params: 6140368 (23.42 MB)\n","Trainable params: 6140368 (23.42 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["****Q4: one extra layer, forward direction****"],"metadata":{"id":"zf19t5UU0fbA"}},{"cell_type":"code","source":["model2 = create_custom_model(1, False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qsIpG9Tm0pbg","executionInfo":{"status":"ok","timestamp":1712323657727,"user_tz":-180,"elapsed":948,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"7f378cda-eb9a-4f7b-a6a5-e9735d967dc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_1 (Embedding)     (None, None, 300)         3000000   \n","                                                                 \n"," lstm_1 (LSTM)               (None, None, 256)         570368    \n","                                                                 \n"," lstm_2 (LSTM)               (None, None, 256)         525312    \n","                                                                 \n"," time_distributed_1 (TimeDi  (None, None, 10000)       2570000   \n"," stributed)                                                      \n","                                                                 \n","=================================================================\n","Total params: 6665680 (25.43 MB)\n","Trainable params: 6665680 (25.43 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["****Q4: No extra layers, backward ****"],"metadata":{"id":"C26RwXQz0uek"}},{"cell_type":"code","source":["model3 = create_custom_model(None, True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pr7nGb3o1JTu","executionInfo":{"status":"ok","timestamp":1712323659781,"user_tz":-180,"elapsed":837,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"08758428-c135-4422-ce02-66ffc2d4cead"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_2 (Embedding)     (None, None, 300)         3000000   \n","                                                                 \n"," lstm_3 (LSTM)               (None, None, 256)         570368    \n","                                                                 \n"," time_distributed_2 (TimeDi  (None, None, 10000)       2570000   \n"," stributed)                                                      \n","                                                                 \n","=================================================================\n","Total params: 6140368 (23.42 MB)\n","Trainable params: 6140368 (23.42 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["****Q4: One extra layer, backward****"],"metadata":{"id":"Jr3wd4Qw1e7x"}},{"cell_type":"code","source":["model4 = create_custom_model(1, True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7lwET6nP1a0u","executionInfo":{"status":"ok","timestamp":1712323661637,"user_tz":-180,"elapsed":795,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"d77a1e8f-dfd2-4f18-e6e8-1bd4ff399288"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_3 (Embedding)     (None, None, 300)         3000000   \n","                                                                 \n"," lstm_4 (LSTM)               (None, None, 256)         570368    \n","                                                                 \n"," lstm_5 (LSTM)               (None, None, 256)         525312    \n","                                                                 \n"," time_distributed_3 (TimeDi  (None, None, 10000)       2570000   \n"," stributed)                                                      \n","                                                                 \n","=================================================================\n","Total params: 6665680 (25.43 MB)\n","Trainable params: 6665680 (25.43 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["****Q5: Function of probability****"],"metadata":{"id":"BEru9bWU1nmM"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","def sentence_probability(model, sentence):\n","    indices = []\n","    for word in sentence.split():\n","        if word not in w2i:\n","            indices.append(w2i['<UNK>'])\n","        else:\n","            indices.append(w2i[word])\n","\n","    # Insert the start symbol index (1) at the beginning of the indices\n","    indices.insert(0, 1)\n","\n","    # Convert the list of indices to a numpy array\n","    indices = np.array(indices)\n","\n","    # Make a prediction using the model\n","    predictions = model.predict(indices[None, :])\n","\n","    # Apply softmax activation to get probabilities\n","    softmax = tf.keras.layers.Softmax()\n","    probabilities = softmax(predictions)\n","\n","    # Calculate the probability of the sentence\n","    sentence_probability = np.exp(np.sum(np.log([probabilities[0][i + 1][indices[i]] for i in range(len(indices) - 1)])))\n","\n","    print(\"The probability of '{}': {}\".format(sentence, sentence_probability))\n","\n","    return sentence_probability\n","\n","\n"],"metadata":{"id":"_DJ1IVuG1zvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_model(model1, 'model1 - train')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPQqlr4e6aom","executionInfo":{"status":"ok","timestamp":1712323844226,"user_tz":-180,"elapsed":179215,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"5bb365e4-e9c7-46b3-c4cd-cce66807bdea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:38<00:00,  4.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.251443386077881\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 25.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.88588285446167\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 26.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.6782684326171875\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 25.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.519617557525635\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 26.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.388356685638428\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 25.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.267702579498291\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 25.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.16424036026001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 25.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.069571018218994\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.9825921058654785\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.900674343109131\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 25.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.820597171783447\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.745187282562256\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.673551559448242\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.601725101470947\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.53444242477417\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.469528675079346\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 25.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.411933898925781\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 25.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.357798099517822\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.305532932281494\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.19it/s]"]},{"output_type":"stream","name":"stdout","text":["4.247199058532715\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["4.247199058532715"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["train_model(model2, 'model2 - train')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QHlDDUwy6uMI","executionInfo":{"status":"ok","timestamp":1712324029252,"user_tz":-180,"elapsed":185042,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"69311624-335f-4b62-f736-deb5f1c0b90f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:27<00:00,  6.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.5347418785095215\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.514420509338379\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.466787338256836\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.19122838973999\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 21.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.03316068649292\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.949459552764893\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.889650344848633\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 23.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.832962989807129\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.773442268371582\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.717691421508789\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.661379814147949\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.59221887588501\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.522917747497559\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.455658435821533\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 21.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.391873836517334\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 21.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.325836181640625\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.258880615234375\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.199428081512451\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.1444902420043945\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.53it/s]"]},{"output_type":"stream","name":"stdout","text":["5.098410606384277\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["5.098410606384277"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["train_model(model3, 'model3 - train')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RBqiw0M61wy","executionInfo":{"status":"ok","timestamp":1712324197633,"user_tz":-180,"elapsed":168401,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"3b618d46-74ad-4323-a1a5-d7bcbd209b08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:24<00:00,  7.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.379228591918945\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 25.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.282315254211426\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 23.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.220735549926758\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.195218086242676\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 23.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.160033702850342\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.116074562072754\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.060958385467529\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.002007484436035\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.945425033569336\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.887324810028076\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 25.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.81635856628418\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.739992141723633\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.666952133178711\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.585628032684326\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.518144607543945\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.441370487213135\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.365584373474121\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.301890850067139\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 25.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.22584867477417\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:07<00:00, 24.10it/s]"]},{"output_type":"stream","name":"stdout","text":["5.147737503051758\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["5.147737503051758"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["train_model(model4, 'model4 - train')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t84CIr5x65_F","executionInfo":{"status":"ok","timestamp":1712324384883,"user_tz":-180,"elapsed":187269,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"67f20e8a-aeed-45d4-edcd-6f3d0f4d1b15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:27<00:00,  6.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.362420082092285\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["6.239293575286865\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.600415229797363\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["5.026319980621338\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 21.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.532773971557617\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["4.133639335632324\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["3.850419044494629\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["3.559657335281372\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:09<00:00, 20.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["3.1758532524108887\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 21.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["2.814033269882202\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["2.5398175716400146\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["2.315072536468506\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["2.114975690841675\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.9208892583847046\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.7473849058151245\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 21.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.5838741064071655\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 21.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.4298782348632812\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.302207350730896\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["1.1728485822677612\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 186/186 [00:08<00:00, 22.56it/s]"]},{"output_type":"stream","name":"stdout","text":["1.0640184879302979\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["1.0640184879302979"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["****Q6: ****"],"metadata":{"id":"rG1Zw94E2Qas"}},{"cell_type":"code","source":["import numpy as np\n","\n","def generate_sentence(model):\n","    all_sentences = []\n","    seed = [w2i[\"i\"], w2i[\"love\"]]\n","    seed = np.insert(seed, 0, 1)\n","    temperatures = [0.1, 1, 10]\n","    for temp in temperatures:\n","        generated_sequence = generate_seq(model, seed, 7, temperature=temp)\n","        generated_sentence = decode(generated_sequence[1:])  # Exclude padding\n","        print('For temperature =', temp, ':', generated_sentence)\n","        all_sentences.append(generated_sentence)\n","    return all_sentences\n","\n","\n"],"metadata":{"id":"Y-Wdg1472Odj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","sentence1 = generate_sentence(model1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_RkhNTZT7GIE","executionInfo":{"status":"ok","timestamp":1712326275041,"user_tz":-180,"elapsed":987,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"1c91ca9c-94a9-41d8-fcef-d7352c379b4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","For temperature = 0.1 : i love lrb born september 13\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6f16fd6f58d8>:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  tokens[i] = next_token\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 17ms/step\n","For temperature = 1 : i love ferry may known as\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","For temperature = 10 : i love olympiad lighting naval announces\n"]}]},{"cell_type":"code","source":["\n","sentence2 = generate_sentence(model2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lNZqmEeWfunE","executionInfo":{"status":"ok","timestamp":1712326277043,"user_tz":-180,"elapsed":938,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"b464c9f5-ca77-464d-8c7b-3e45602a62fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","For temperature = 0.1 : i love is a <UNK> of\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6f16fd6f58d8>:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  tokens[i] = next_token\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","For temperature = 1 : i love is a book and\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 21ms/step\n","For temperature = 10 : i love argentina fold showed bobby\n"]}]},{"cell_type":"code","source":["\n","sentences3 = generate_sentence(model3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K02jkxfZfxLs","executionInfo":{"status":"ok","timestamp":1712326278409,"user_tz":-180,"elapsed":1023,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"2090bae1-7d69-42e1-a33f-ed6e719efa64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6f16fd6f58d8>:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  tokens[i] = next_token\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 20ms/step\n","For temperature = 0.1 : i love <UNK> <UNK> <UNK> <UNK>\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","For temperature = 1 : i love commonly and as and\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","For temperature = 10 : i love rivers mardan sint 1992\n"]}]},{"cell_type":"code","source":["\n","sentence4 = generate_sentence(model4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j46Uaqamfz0d","executionInfo":{"status":"ok","timestamp":1712326280158,"user_tz":-180,"elapsed":619,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"ad2bc329-9d7d-4423-9f20-26574a763daf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 18ms/step\n","For temperature = 0.1 : i love <PAD> <PAD> <PAD> <PAD>\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-6f16fd6f58d8>:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  tokens[i] = next_token\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","For temperature = 1 : i love <PAD> <PAD> <PAD> <PAD>\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","For temperature = 10 : i love marine orbit powers socialist\n"]}]},{"cell_type":"markdown","source":["****Q7****"],"metadata":{"id":"NICAMoKV2aUj"}},{"cell_type":"code","source":["from scipy.special import logsumexp\n","\n","def predict_next_word(model, num_model):\n","    while True:\n","        word = input(\"Please enter a word: \")\n","        if word in w2i:\n","            break\n","        else:\n","            print(\"Word not found in vocabulary. Please enter another word.\")\n","\n","    token = w2i[word]\n","    token = np.insert(token, 0, 1)\n","    pred = model.predict(token[None, :])\n","    pred = pred[0][1]\n","    pred = np.asarray(pred).astype('float64')\n","    pred = pred - logsumexp(pred)\n","    next_token = int(np.random.choice(len(pred), 1, p=np.exp(pred)))\n","    print(\"The next word for model\", num_model, \":\", i2w[next_token])\n","\n","\n","\n"],"metadata":{"id":"GayS2apm2dAj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lpredict_next_word(model1,1)\n","predict_next_word(model2,2)\n","predict_next_word(model3,3)\n","predict_next_word(model4,4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vAmifAfR8m3","executionInfo":{"status":"ok","timestamp":1712326176323,"user_tz":-180,"elapsed":15272,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"4c072062-9417-499f-f247-9703d545f754"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter a word: love\n","1/1 [==============================] - 0s 17ms/step\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-63-7d8805bfeab7>:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n","  next_token = int(np.random.choice(len(pred), 1, p=np.exp(pred)))\n"]},{"output_type":"stream","name":"stdout","text":["The next word for model 1 : ''\n","Please enter a word: love\n","1/1 [==============================] - 0s 19ms/step\n","The next word for model 2 : khan\n","Please enter a word: ove\n","Word not found in vocabulary. Please enter another word.\n","Please enter a word: love\n","1/1 [==============================] - 0s 20ms/step\n","The next word for model 3 : 1998\n","Please enter a word: love\n","1/1 [==============================] - 0s 33ms/step\n","The next word for model 4 : majority\n"]}]},{"cell_type":"markdown","source":["****Q7:perplexity****"],"metadata":{"id":"an9uE80QiOOX"}},{"cell_type":"code","source":["def perplexityCalc(model, title, data_loader):\n","    total_loss = 0\n","    total_batches = len(data_loader)\n","\n","    for batch in data_loader:\n","        # Prepare the batch\n","        shifted_batch = np.concatenate([np.ones((batch.shape[0], 1)), batch], axis=1)\n","        output_batch = np.concatenate([batch, np.zeros((batch.shape[0], 1))], axis=1)\n","\n","        # Compute the loss\n","        batch_loss = model.test_on_batch(shifted_batch, output_batch[:, :, None])\n","        total_loss += batch_loss\n","\n","    average_loss = total_loss / total_batches\n","    perplexity_score = calculate_perplexity(average_loss)\n","\n","    print(\"Perplexity for\", title, \"is\", perplexity_score)\n","    return perplexity_score"],"metadata":{"id":"H7YqhvZ6jbOR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["perplexityCalc(model1, 'model1 - train', train_data)\n","perplexityCalc(model1, 'model1 - validation', valid_data)\n","perplexityCalc(model1, 'model1 - test', test_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-bTsNlZiQcs","executionInfo":{"status":"ok","timestamp":1712326191803,"user_tz":-180,"elapsed":5149,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"e5a1a0a4-2b61-4dcf-d696-3cce17748165"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity for model1 - train is 16.847341698937555\n","Perplexity for model1 - validation is 32.544042806305384\n","Perplexity for model1 - test is 34.362245875111334\n"]},{"output_type":"execute_result","data":{"text/plain":["34.362245875111334"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["perplexityCalc(model2, 'model2 - train', train_data)\n","perplexityCalc(model2, 'model2 - validation', valid_data)\n","perplexityCalc(model2, 'model2 - test', test_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wQuHxyRJj8kz","executionInfo":{"status":"ok","timestamp":1712326198798,"user_tz":-180,"elapsed":5180,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"23436990-db7f-41b4-80d6-ce14b46ba675"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity for model2 - train is 30.431955304834997\n","Perplexity for model2 - validation is 37.83264270302552\n","Perplexity for model2 - test is 39.362068402874264\n"]},{"output_type":"execute_result","data":{"text/plain":["39.362068402874264"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["perplexityCalc(model3, 'model3 - train', train_data)\n","perplexityCalc(model3, 'model3 - validation', valid_data)\n","perplexityCalc(model3, 'model3 - test', test_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TuHsT9e_kF9U","executionInfo":{"status":"ok","timestamp":1712326203752,"user_tz":-180,"elapsed":4508,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"ab76186b-cc71-4c86-d354-6fbb24b17321"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity for model3 - train is 29.0170034623388\n","Perplexity for model3 - validation is 54.09547233464761\n","Perplexity for model3 - test is 56.201167398603474\n"]},{"output_type":"execute_result","data":{"text/plain":["56.201167398603474"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["perplexityCalc(model4, 'model4 - train', train_data)\n","perplexityCalc(model4, 'model4 - validation', valid_data)\n","perplexityCalc(model4, 'model4 - test', test_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hSkj8xhHkO8I","executionInfo":{"status":"ok","timestamp":1712326209610,"user_tz":-180,"elapsed":4957,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"bc295fa6-0aff-4adb-dc78-fd43b574252c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity for model4 - train is 2.0725369214509572\n","Perplexity for model4 - validation is 2.284337814627195\n","Perplexity for model4 - test is 2.349796069730992\n"]},{"output_type":"execute_result","data":{"text/plain":["2.349796069730992"]},"metadata":{},"execution_count":69}]},{"cell_type":"markdown","source":["****Q9****"],"metadata":{"id":"Pho-5M8ekX0t"}},{"cell_type":"code","source":["def calculate_probabilities(model,sentences):\n","  for sentence in sentences:\n","    sentence_probability(model, sentence)\n","  sentence_probability(model, \"i love cupcakes\")\n"],"metadata":{"id":"Wm63mi8jkadG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calculate_probabilities(model1,sentence1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqgO0NjLlWuX","executionInfo":{"status":"ok","timestamp":1712327445326,"user_tz":-180,"elapsed":465,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"4067f6b4-d7d4-4d40-e40c-4814607ce9d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 31ms/step\n","The probability of 'i love lrb born september 13': 1.5662308187623152e-25\n","1/1 [==============================] - 0s 33ms/step\n","The probability of 'i love ferry may known as': 7.116009774993139e-26\n","1/1 [==============================] - 0s 26ms/step\n","The probability of 'i love olympiad lighting naval announces': 2.384795684075354e-31\n","1/1 [==============================] - 0s 36ms/step\n","The probability of 'i love cupcakes': 3.581439954173683e-14\n"]}]},{"cell_type":"code","source":["calculate_probabilities(model2,sentence2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rW1jLD4Oq1xf","executionInfo":{"status":"ok","timestamp":1712327461942,"user_tz":-180,"elapsed":1515,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"9b976bd3-d62d-4d7f-8890-1e43763e5c90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 1s/step\n","The probability of 'i love is a <UNK> of': 5.48605364818028e-23\n","1/1 [==============================] - 0s 29ms/step\n","The probability of 'i love is a book and': 1.6230837776825606e-25\n","1/1 [==============================] - 0s 32ms/step\n","The probability of 'i love argentina fold showed bobby': 3.203958999889377e-29\n","1/1 [==============================] - 0s 30ms/step\n","The probability of 'i love cupcakes': 2.3230926781721414e-15\n"]}]},{"cell_type":"code","source":["calculate_probabilities(model3,sentences3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6sYXjqNWq5Lp","executionInfo":{"status":"ok","timestamp":1712327486560,"user_tz":-180,"elapsed":1104,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"731b1189-1c9f-40bf-89b6-03dfcddbf5d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 598ms/step\n","The probability of 'i love <UNK> <UNK> <UNK> <UNK>': 6.80331290105277e-19\n","1/1 [==============================] - 0s 30ms/step\n","The probability of 'i love commonly and as and': 2.2844599288468124e-23\n","1/1 [==============================] - 0s 31ms/step\n","The probability of 'i love rivers mardan sint 1992': 7.656385558777207e-33\n","1/1 [==============================] - 0s 43ms/step\n","The probability of 'i love cupcakes': 9.825106559297666e-18\n"]}]},{"cell_type":"code","source":["calculate_probabilities(model4,sentence4)"],"metadata":{"id":"WhiQM5wbq_NA","executionInfo":{"status":"ok","timestamp":1712327499391,"user_tz":-180,"elapsed":1581,"user":{"displayName":"דניאל סולימן","userId":"08227043455214053432"}},"outputId":"74ad6033-354c-4278-8ffa-07a800384977","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 988ms/step\n","The probability of 'i love <PAD> <PAD> <PAD> <PAD>': 5.861934964304939e-20\n","1/1 [==============================] - 0s 19ms/step\n","The probability of 'i love <PAD> <PAD> <PAD> <PAD>': 5.861934964304939e-20\n","1/1 [==============================] - 0s 18ms/step\n","The probability of 'i love marine orbit powers socialist': 8.44317830295672e-36\n","1/1 [==============================] - 0s 21ms/step\n","The probability of 'i love cupcakes': 2.1848752325769792e-23\n"]}]}]}